{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de Bibliotecas\n",
    "pip install pandas numpy matplotlib scikit-learn tensorflow keras seaborn optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importação de Bibliotecas\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, SpatialDropout1D, SimpleRNN, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "df = pd.read_csv(\"C:/Users/ana_v/OneDrive/Documentos/Repositórios/GSE25066.csv\", low_memory=False)\n",
    "\n",
    "# Obtém os valores únicos na coluna 'Type'\n",
    "unique_types = df['type'].unique()\n",
    "\n",
    "# Cria um dicionário mapeando cada tipo único para um número\n",
    "type_to_numeric = {type_name: index for index, type_name in enumerate(unique_types)}\n",
    "\n",
    "# Aplica a substituição usando o método map\n",
    "df['type'] = df['type'].map(type_to_numeric)\n",
    "\n",
    "# Armazena a coluna 'type' para adicioná-la de volta posteriormente\n",
    "type_column = df['type']\n",
    "\n",
    "# Prepara o DataFrame para normalização (remover colunas desnecessárias)\n",
    "df_num = df.drop(columns=[\"sample\", \"type\"])\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicação do PCA\n",
    "pca = PCA(n_components=0.8)  \n",
    "pca.fit(dados_normalizados)\n",
    "dados_pca = pca.transform(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixar a seed para garantir a reprodutibilidade\n",
    "seed = 1\n",
    "\n",
    "# Divisão de treino e teste com random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados_pca, df['type'], test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 16:30:40,743] A new study created in memory with name: no-name-d753e999-d2dd-4b25-827f-a0d6cefbf3b1\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:40,874] Trial 0 finished with value: 0.7907926829268292 and parameters: {'svc_c': 0.008301451461243867, 'svc_kernel': 'linear'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,028] Trial 1 finished with value: 0.3670731707317073 and parameters: {'svc_c': 4.429657657076251e-05, 'svc_kernel': 'sigmoid'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,224] Trial 2 finished with value: 0.3670731707317073 and parameters: {'svc_c': 0.008597290483171273, 'svc_kernel': 'rbf'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,420] Trial 3 finished with value: 0.42128048780487803 and parameters: {'svc_c': 0.4934834261073345, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,524] Trial 4 finished with value: 0.7907926829268292 and parameters: {'svc_c': 4.029136499667933, 'svc_kernel': 'linear'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,647] Trial 5 finished with value: 0.7688414634146341 and parameters: {'svc_c': 18.291387257048378, 'svc_kernel': 'sigmoid'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,787] Trial 6 finished with value: 0.3670731707317073 and parameters: {'svc_c': 4.880090060376772e-05, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:41,939] Trial 7 finished with value: 0.3670731707317073 and parameters: {'svc_c': 0.0016166254707399778, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7907926829268292.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:42,147] Trial 8 finished with value: 0.7933536585365853 and parameters: {'svc_c': 83.56561666138207, 'svc_kernel': 'rbf'}. Best is trial 8 with value: 0.7933536585365853.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:30:42,275] Trial 9 finished with value: 0.7907926829268292 and parameters: {'svc_c': 0.013653836035069419, 'svc_kernel': 'linear'}. Best is trial 8 with value: 0.7933536585365853.\n",
      "[I 2024-08-30 16:30:42,277] A new study created in memory with name: no-name-6f425950-cf98-485f-b024-48afea302500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para SVM: {'svc_c': 83.56561666138207, 'svc_kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 16:30:47,279] Trial 0 finished with value: 0.6231707317073171 and parameters: {'rf_n_estimators': 112, 'rf_max_depth': 39, 'rf_min_samples_split': 2}. Best is trial 0 with value: 0.6231707317073171.\n",
      "[I 2024-08-30 16:30:51,280] Trial 1 finished with value: 0.6333536585365854 and parameters: {'rf_n_estimators': 95, 'rf_max_depth': 16, 'rf_min_samples_split': 3}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:30:54,484] Trial 2 finished with value: 0.6309146341463415 and parameters: {'rf_n_estimators': 78, 'rf_max_depth': 24, 'rf_min_samples_split': 9}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:30:59,612] Trial 3 finished with value: 0.6235975609756098 and parameters: {'rf_n_estimators': 131, 'rf_max_depth': 27, 'rf_min_samples_split': 15}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:31:03,706] Trial 4 finished with value: 0.6134756097560976 and parameters: {'rf_n_estimators': 80, 'rf_max_depth': 46, 'rf_min_samples_split': 2}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:31:10,128] Trial 5 finished with value: 0.6210365853658536 and parameters: {'rf_n_estimators': 151, 'rf_max_depth': 27, 'rf_min_samples_split': 12}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:31:12,737] Trial 6 finished with value: 0.6088414634146341 and parameters: {'rf_n_estimators': 71, 'rf_max_depth': 18, 'rf_min_samples_split': 17}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:31:20,123] Trial 7 finished with value: 0.6163414634146342 and parameters: {'rf_n_estimators': 196, 'rf_max_depth': 22, 'rf_min_samples_split': 15}. Best is trial 1 with value: 0.6333536585365854.\n",
      "[I 2024-08-30 16:31:27,848] Trial 8 finished with value: 0.6405487804878048 and parameters: {'rf_n_estimators': 182, 'rf_max_depth': 46, 'rf_min_samples_split': 3}. Best is trial 8 with value: 0.6405487804878048.\n",
      "[I 2024-08-30 16:31:29,815] Trial 9 finished with value: 0.6162195121951219 and parameters: {'rf_n_estimators': 55, 'rf_max_depth': 16, 'rf_min_samples_split': 18}. Best is trial 8 with value: 0.6405487804878048.\n",
      "[I 2024-08-30 16:31:29,816] A new study created in memory with name: no-name-e00b0ee5-00a5-4555-86a2-5f2ea8d034a2\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Random Forest: {'rf_n_estimators': 182, 'rf_max_depth': 46, 'rf_min_samples_split': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 16:31:30,258] Trial 0 finished with value: 0.7859146341463414 and parameters: {'lr_c': 0.008301451461243867, 'lr_solver': 'newton-cg'}. Best is trial 0 with value: 0.7859146341463414.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:31:43,190] Trial 1 finished with value: 0.778719512195122 and parameters: {'lr_c': 4.429657657076251e-05, 'lr_solver': 'saga'}. Best is trial 0 with value: 0.7859146341463414.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:31:44,867] Trial 2 finished with value: 0.6410365853658536 and parameters: {'lr_c': 0.008597290483171273, 'lr_solver': 'liblinear'}. Best is trial 0 with value: 0.7859146341463414.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:31:45,049] Trial 3 finished with value: 0.7759756097560977 and parameters: {'lr_c': 0.4934834261073345, 'lr_solver': 'lbfgs'}. Best is trial 0 with value: 0.7859146341463414.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:31:45,277] Trial 4 finished with value: 0.7735365853658538 and parameters: {'lr_c': 4.029136499667933, 'lr_solver': 'newton-cg'}. Best is trial 0 with value: 0.7859146341463414.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:32:15,040] Trial 5 finished with value: 0.7882926829268293 and parameters: {'lr_c': 18.291387257048378, 'lr_solver': 'saga'}. Best is trial 5 with value: 0.7882926829268293.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:32:15,328] Trial 6 finished with value: 0.7615853658536585 and parameters: {'lr_c': 4.880090060376772e-05, 'lr_solver': 'lbfgs'}. Best is trial 5 with value: 0.7882926829268293.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:32:15,658] Trial 7 finished with value: 0.7833536585365855 and parameters: {'lr_c': 0.0016166254707399778, 'lr_solver': 'lbfgs'}. Best is trial 5 with value: 0.7882926829268293.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:32:19,679] Trial 8 finished with value: 0.5620121951219513 and parameters: {'lr_c': 83.56561666138207, 'lr_solver': 'liblinear'}. Best is trial 5 with value: 0.7882926829268293.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\2525961298.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 16:32:20,052] Trial 9 finished with value: 0.7883536585365853 and parameters: {'lr_c': 0.013653836035069419, 'lr_solver': 'newton-cg'}. Best is trial 9 with value: 0.7883536585365853.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Regressão Logística: {'lr_c': 0.013653836035069419, 'lr_solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# Função objetivo para otimização do SVM\n",
    "def objective_svm(trial):\n",
    "    svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
    "    svc_kernel = trial.suggest_categorical('svc_kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    \n",
    "    model_svm = SVC(C=svc_c, kernel=svc_kernel, random_state=seed)\n",
    "    score = cross_val_score(model_svm, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Função objetivo para otimização do Random Forest\n",
    "def objective_rf(trial):\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 50, 200)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 10, 50)\n",
    "    rf_min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 20)\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=rf_n_estimators, max_depth=rf_max_depth,\n",
    "                                      min_samples_split=rf_min_samples_split, random_state=seed)\n",
    "    score = cross_val_score(model_rf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Função objetivo para otimização da Regressão Logística\n",
    "def objective_lr(trial):\n",
    "    lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
    "    lr_solver = trial.suggest_categorical('lr_solver', ['newton-cg', 'lbfgs', 'liblinear', 'saga'])\n",
    "    \n",
    "    model_lr = LogisticRegression(C=lr_c, solver=lr_solver, max_iter=10000, random_state=seed)\n",
    "    score = cross_val_score(model_lr, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Estudo e otimização com Optuna para SVM\n",
    "study_svm = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_svm.optimize(objective_svm, n_trials=10)\n",
    "best_params_svm = study_svm.best_params\n",
    "print(\"Melhores parâmetros para SVM:\", best_params_svm)\n",
    "\n",
    "# Estudo e otimização com Optuna para Random Forest\n",
    "study_rf = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_rf.optimize(objective_rf, n_trials=10)\n",
    "best_params_rf = study_rf.best_params\n",
    "print(\"Melhores parâmetros para Random Forest:\", best_params_rf)\n",
    "\n",
    "# Estudo e otimização com Optuna para Regressão Logística\n",
    "study_lr = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_lr.optimize(objective_lr, n_trials=10)\n",
    "best_params_lr = study_lr.best_params\n",
    "print(\"Melhores parâmetros para Regressão Logística:\", best_params_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Acurácia (Treinamento): 1.0\n",
      "SVM - Acurácia (Teste): 0.7745098039215687\n",
      "Acurácia média na validação cruzada: 0.7933536585365853\n",
      "\n",
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.80        34\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       1.00      0.88      0.93        40\n",
      "           3       0.67      0.46      0.55        13\n",
      "           4       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.77       102\n",
      "   macro avg       0.67      0.61      0.63       102\n",
      "weighted avg       0.78      0.77      0.77       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[32  0  0  2  0]\n",
      " [ 2  4  0  0  2]\n",
      " [ 2  1 35  0  2]\n",
      " [ 7  0  0  6  0]\n",
      " [ 3  1  0  1  2]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo SVM com os melhores parâmetros\n",
    "best_model_svm = SVC(C=best_params_svm['svc_c'], kernel=best_params_svm['svc_kernel'], random_state=seed)\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "svm_predictions_train = best_model_svm.predict(X_train)\n",
    "svm_predictions_test = best_model_svm.predict(X_test)\n",
    "\n",
    "# Avaliação SVM\n",
    "svm_accuracy_train = accuracy_score(y_train, svm_predictions_train)\n",
    "svm_accuracy_test = accuracy_score(y_test, svm_predictions_test)\n",
    "svm_report = classification_report(y_test, svm_predictions_test, zero_division=1)\n",
    "\n",
    "# Resultados\n",
    "print(f'SVM - Acurácia (Treinamento): {svm_accuracy_train}')\n",
    "print(f'SVM - Acurácia (Teste): {svm_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_svm, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (SVM):\\n{svm_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, svm_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Acurácia (Teste): 0.696078431372549\n",
      "Acurácia média na validação cruzada: 0.6405487804878048\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.72        34\n",
      "           1       1.00      0.12      0.22         8\n",
      "           2       0.75      0.97      0.85        40\n",
      "           3       1.00      0.15      0.27        13\n",
      "           4       1.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.70       102\n",
      "   macro avg       0.87      0.42      0.41       102\n",
      "weighted avg       0.77      0.70      0.62       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[29  0  5  0  0]\n",
      " [ 5  1  2  0  0]\n",
      " [ 1  0 39  0  0]\n",
      " [ 8  0  3  2  0]\n",
      " [ 4  0  3  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo Random Forest com os melhores parâmetros\n",
    "best_model_rf = RandomForestClassifier(\n",
    "    n_estimators=best_params_rf['rf_n_estimators'],\n",
    "    max_depth=best_params_rf['rf_max_depth'],\n",
    "    min_samples_split=best_params_rf['rf_min_samples_split'],\n",
    "    random_state=seed\n",
    ")\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "rf_predictions_train = best_model_rf.predict(X_train)\n",
    "rf_predictions_test = best_model_rf.predict(X_test)\n",
    "\n",
    "# Avaliação Random Forest\n",
    "rf_accuracy_train = accuracy_score(y_train, rf_predictions_train)\n",
    "rf_accuracy_test = accuracy_score(y_test, rf_predictions_test)\n",
    "rf_report = classification_report(y_test, rf_predictions_test, zero_division=1)\n",
    "\n",
    "print(f'Random Forest - Acurácia (Teste): {rf_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_rf, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (Random Forest):\\n{rf_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, rf_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.803921568627451\n",
      "Acurácia média na validação cruzada: 0.7883536585365853\n",
      "\n",
      "Classification Report (Regressão Logística):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        34\n",
      "           1       0.62      0.62      0.62         8\n",
      "           2       1.00      0.90      0.95        40\n",
      "           3       0.62      0.77      0.69        13\n",
      "           4       0.43      0.43      0.43         7\n",
      "\n",
      "    accuracy                           0.80       102\n",
      "   macro avg       0.70      0.71      0.70       102\n",
      "weighted avg       0.82      0.80      0.81       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[28  1  0  4  1]\n",
      " [ 1  5  0  0  2]\n",
      " [ 1  2 36  0  1]\n",
      " [ 3  0  0 10  0]\n",
      " [ 2  0  0  2  3]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo Regressão Logística com os melhores parâmetros\n",
    "best_model_lr = LogisticRegression(\n",
    "    C=best_params_lr['lr_c'],\n",
    "    solver=best_params_lr['lr_solver'],\n",
    "    max_iter=10000,\n",
    "    random_state=seed\n",
    ")\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "lr_predictions_train = best_model_lr.predict(X_train)\n",
    "lr_predictions_test = best_model_lr.predict(X_test)\n",
    "\n",
    "# Avaliação Regressão Logística\n",
    "lr_accuracy_train = accuracy_score(y_train, lr_predictions_train)\n",
    "lr_accuracy_test = accuracy_score(y_test, lr_predictions_test)\n",
    "lr_report = classification_report(y_test, lr_predictions_test)\n",
    "\n",
    "print(f'Regressão Logística - Acurácia (Teste): {lr_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_lr, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (Regressão Logística):\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, lr_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 16:33:13,161] A new study created in memory with name: no-name-8a5739f9-c6e9-4d57-b44b-a30621f9daf1\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:33:14,986] Trial 0 finished with value: 0.36663655525444144 and parameters: {'n_layers': 4, 'n_units_l0': 115, 'n_units_l1': 25, 'n_units_l2': 63, 'n_units_l3': 43, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00047509237210306113, 'learning_rate_init': 0.011367330868956235}. Best is trial 0 with value: 0.36663655525444144.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-30 16:33:27,727] Trial 1 finished with value: 0.71162300511894 and parameters: {'n_layers': 3, 'n_units_l0': 135, 'n_units_l1': 28, 'n_units_l2': 109, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0746528346269155, 'learning_rate_init': 0.0008715103205978142}. Best is trial 1 with value: 0.71162300511894.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:33:31,000] Trial 2 finished with value: 0.6846431797651309 and parameters: {'n_layers': 5, 'n_units_l0': 135, 'n_units_l1': 137, 'n_units_l2': 35, 'n_units_l3': 29, 'n_units_l4': 46, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.005854751355295724, 'learning_rate_init': 0.0008841926348917736}. Best is trial 1 with value: 0.71162300511894.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-30 16:33:56,317] Trial 3 finished with value: 0.6993676603432701 and parameters: {'n_layers': 5, 'n_units_l0': 130, 'n_units_l1': 27, 'n_units_l2': 119, 'n_units_l3': 149, 'n_units_l4': 119, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0001494364677378836, 'learning_rate_init': 0.0007300053042915264}. Best is trial 1 with value: 0.71162300511894.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-30 16:34:09,708] Trial 4 finished with value: 0.7806383619391749 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'n_units_l1': 110, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 3.862907418494322e-05, 'learning_rate_init': 0.005860256303804338}. Best is trial 4 with value: 0.7806383619391749.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:34:23,244] Trial 5 finished with value: 0.5812104787714543 and parameters: {'n_layers': 5, 'n_units_l0': 37, 'n_units_l1': 77, 'n_units_l2': 112, 'n_units_l3': 77, 'n_units_l4': 31, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.04107784588077006, 'learning_rate_init': 0.0002584783141380735}. Best is trial 4 with value: 0.7806383619391749.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:34:29,736] Trial 6 finished with value: 0.7781692261367058 and parameters: {'n_layers': 2, 'n_units_l0': 126, 'n_units_l1': 75, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.034136922393519724, 'learning_rate_init': 0.007430475750099704}. Best is trial 4 with value: 0.7806383619391749.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:34:31,753] Trial 7 finished with value: 0.6894007828967179 and parameters: {'n_layers': 5, 'n_units_l0': 68, 'n_units_l1': 59, 'n_units_l2': 137, 'n_units_l3': 78, 'n_units_l4': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.002058535957997779, 'learning_rate_init': 0.0016765264451568493}. Best is trial 4 with value: 0.7806383619391749.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:34:40,219] Trial 8 finished with value: 0.7633242999096657 and parameters: {'n_layers': 3, 'n_units_l0': 138, 'n_units_l1': 97, 'n_units_l2': 25, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.04306660168805714, 'learning_rate_init': 0.007414474013266335}. Best is trial 4 with value: 0.7806383619391749.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\3373024165.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 16:34:41,327] Trial 9 finished with value: 0.7313760915386932 and parameters: {'n_layers': 2, 'n_units_l0': 142, 'n_units_l1': 112, 'activation': 'relu', 'solver': 'adam', 'alpha': 1.8365412649690993e-05, 'learning_rate_init': 0.018466694211779083}. Best is trial 4 with value: 0.7806383619391749.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para MLP: {'n_layers': 2, 'n_units_l0': 27, 'n_units_l1': 110, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 3.862907418494322e-05, 'learning_rate_init': 0.005860256303804338}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Função objetivo para otimização do MLP\n",
    "def objective_mlp(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 6)\n",
    "    hidden_layer_sizes = [trial.suggest_int(f'n_units_l{i}', 25, 150) for i in range(n_layers)]\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n",
    "    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
    "    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
    "    \n",
    "    # Criar e treinar o modelo\n",
    "    model = MLPClassifier(hidden_layer_sizes=tuple(hidden_layer_sizes), activation=activation,\n",
    "                          solver=solver, alpha=alpha, learning_rate_init=learning_rate_init,\n",
    "                          max_iter=500, random_state=seed)\n",
    "    \n",
    "    # Validação cruzada\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Estudo de otimização com Optuna para MLP\n",
    "study_mlp = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_mlp.optimize(objective_mlp, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_mlp = study_mlp.best_params\n",
    "print(\"Melhores parâmetros para MLP:\", best_params_mlp)\n",
    "\n",
    "# Treinamento e avaliação do MLP com os melhores parâmetros\n",
    "best_mlp_model = MLPClassifier(hidden_layer_sizes=tuple(best_params_mlp[f'n_units_l{i}'] for i in range(best_params_mlp['n_layers'])),\n",
    "                               activation=best_params_mlp['activation'],\n",
    "                               solver=best_params_mlp['solver'],\n",
    "                               alpha=best_params_mlp['alpha'],\n",
    "                               learning_rate_init=best_params_mlp['learning_rate_init'],\n",
    "                               max_iter=500, random_state=seed)\n",
    "best_mlp_model.fit(X_train, y_train)\n",
    "mlp_predictions_train = best_mlp_model.predict(X_train)\n",
    "mlp_predictions_test = best_mlp_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo\n",
    "mlp_accuracy_train = accuracy_score(y_train, mlp_predictions_train)\n",
    "mlp_accuracy_test = accuracy_score(y_test, mlp_predictions_test)\n",
    "mlp_report = classification_report(y_test, mlp_predictions_test, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do MLP:\n",
      "Matriz de Confusão:\n",
      " [[31  0  0  2  1]\n",
      " [ 1  6  0  0  1]\n",
      " [ 1  3 36  0  0]\n",
      " [ 4  0  0  8  1]\n",
      " [ 0  2  2  2  1]]\n",
      "Acurácia (Teste): 0.803921568627451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média na validação cruzada (MLP): 0.8007\n",
      "\n",
      "Classification Report (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87        34\n",
      "           1       0.55      0.75      0.63         8\n",
      "           2       0.95      0.90      0.92        40\n",
      "           3       0.67      0.62      0.64        13\n",
      "           4       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.80       102\n",
      "   macro avg       0.65      0.66      0.65       102\n",
      "weighted avg       0.80      0.80      0.80       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Avaliação para MLP\n",
    "print(\"\\nResultados do MLP:\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, mlp_predictions_test))\n",
    "print(\"Acurácia (Teste):\", accuracy_score(y_test, mlp_predictions_test))\n",
    "\n",
    "# Acurácia média na validação cruzada\n",
    "cv_mean_score = cross_val_score(best_mlp_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "print(f'Acurácia média na validação cruzada (MLP): {cv_mean_score:.4f}')\n",
    "\n",
    "# Classification Report\n",
    "print(f'\\nClassification Report (MLP):\\n{mlp_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 16:34:45,303] A new study created in memory with name: no-name-781bd389-e30e-4883-976d-761e1b2fbe30\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_20704\\448404244.py:39: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-08-30 16:34:52,264] Trial 0 finished with value: 0.7192713022232056 and parameters: {'n_conv_layers': 2, 'n_dense_layers': 2, 'filters': 33, 'kernel_size': 3, 'pool_size': 3, 'dense_units': 65, 'dropout_rate': 0.42859391001555774, 'epochs': 13}. Best is trial 0 with value: 0.7192713022232056.\n",
      "[I 2024-08-30 16:35:00,636] Trial 1 finished with value: 0.7024089097976685 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 3, 'filters': 26, 'kernel_size': 2, 'pool_size': 2, 'dense_units': 109, 'dropout_rate': 0.4763570259884, 'epochs': 13}. Best is trial 0 with value: 0.7192713022232056.\n",
      "[I 2024-08-30 16:35:07,200] Trial 2 finished with value: 0.8230051279067994 and parameters: {'n_conv_layers': 4, 'n_dense_layers': 2, 'filters': 29, 'kernel_size': 5, 'pool_size': 3, 'dense_units': 34, 'dropout_rate': 0.2598506948091842, 'epochs': 9}. Best is trial 2 with value: 0.8230051279067994.\n",
      "[I 2024-08-30 16:35:12,580] Trial 3 finished with value: 0.6210478723049164 and parameters: {'n_conv_layers': 2, 'n_dense_layers': 3, 'filters': 57, 'kernel_size': 4, 'pool_size': 3, 'dense_units': 53, 'dropout_rate': 0.35244037938425665, 'epochs': 7}. Best is trial 2 with value: 0.8230051279067994.\n",
      "[I 2024-08-30 16:35:24,567] Trial 4 finished with value: 0.8500451683998108 and parameters: {'n_conv_layers': 4, 'n_dense_layers': 2, 'filters': 58, 'kernel_size': 5, 'pool_size': 3, 'dense_units': 101, 'dropout_rate': 0.3289330317871074, 'epochs': 8}. Best is trial 4 with value: 0.8500451683998108.\n",
      "[I 2024-08-30 16:35:31,575] Trial 5 finished with value: 0.914182472229004 and parameters: {'n_conv_layers': 1, 'n_dense_layers': 3, 'filters': 19, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 120, 'dropout_rate': 0.29245853077739425, 'epochs': 15}. Best is trial 5 with value: 0.914182472229004.\n",
      "[I 2024-08-30 16:35:40,262] Trial 6 finished with value: 0.8403191804885864 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 3, 'filters': 17, 'kernel_size': 3, 'pool_size': 3, 'dense_units': 103, 'dropout_rate': 0.3820760868029911, 'epochs': 17}. Best is trial 5 with value: 0.914182472229004.\n",
      "[I 2024-08-30 16:35:49,397] Trial 7 finished with value: 0.9339054465293884 and parameters: {'n_conv_layers': 2, 'n_dense_layers': 2, 'filters': 20, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 73, 'dropout_rate': 0.2796797209659968, 'epochs': 19}. Best is trial 7 with value: 0.9339054465293884.\n",
      "[I 2024-08-30 16:35:52,890] Trial 8 finished with value: 0.7194218635559082 and parameters: {'n_conv_layers': 1, 'n_dense_layers': 2, 'filters': 18, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 59, 'dropout_rate': 0.3938547880713452, 'epochs': 6}. Best is trial 7 with value: 0.9339054465293884.\n",
      "[I 2024-08-30 16:36:01,591] Trial 9 finished with value: 0.5548931062221527 and parameters: {'n_conv_layers': 1, 'n_dense_layers': 2, 'filters': 60, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 74, 'dropout_rate': 0.48890259603344405, 'epochs': 16}. Best is trial 7 with value: 0.9339054465293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para CNN: {'n_conv_layers': 2, 'n_dense_layers': 2, 'filters': 20, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 73, 'dropout_rate': 0.2796797209659968, 'epochs': 19}\n",
      "Epoch 1/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2591 - loss: 1.9726 - val_accuracy: 0.5490 - val_loss: 1.3361\n",
      "Epoch 2/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4301 - loss: 1.4207 - val_accuracy: 0.5588 - val_loss: 1.1670\n",
      "Epoch 3/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5608 - loss: 1.2008 - val_accuracy: 0.6373 - val_loss: 1.0447\n",
      "Epoch 4/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6518 - loss: 0.9802 - val_accuracy: 0.6275 - val_loss: 0.9692\n",
      "Epoch 5/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6529 - loss: 0.8979 - val_accuracy: 0.6863 - val_loss: 0.8747\n",
      "Epoch 6/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7011 - loss: 0.8120 - val_accuracy: 0.7157 - val_loss: 0.8180\n",
      "Epoch 7/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7604 - loss: 0.6467 - val_accuracy: 0.7157 - val_loss: 0.7894\n",
      "Epoch 8/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8370 - loss: 0.5003 - val_accuracy: 0.7059 - val_loss: 0.7713\n",
      "Epoch 9/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8495 - loss: 0.4458 - val_accuracy: 0.7353 - val_loss: 0.7270\n",
      "Epoch 10/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8836 - loss: 0.3622 - val_accuracy: 0.7255 - val_loss: 0.7564\n",
      "Epoch 11/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.3058 - val_accuracy: 0.7157 - val_loss: 0.7500\n",
      "Epoch 12/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8965 - loss: 0.2790 - val_accuracy: 0.6961 - val_loss: 0.9665\n",
      "Epoch 13/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.1959 - val_accuracy: 0.7451 - val_loss: 0.8180\n",
      "Epoch 14/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9407 - loss: 0.1812 - val_accuracy: 0.7059 - val_loss: 0.7740\n",
      "Epoch 15/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9473 - loss: 0.1546 - val_accuracy: 0.7255 - val_loss: 0.9087\n",
      "Epoch 16/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9418 - loss: 0.2120 - val_accuracy: 0.7157 - val_loss: 0.8387\n",
      "Epoch 17/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.1366 - val_accuracy: 0.7549 - val_loss: 0.8787\n",
      "Epoch 18/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.1201 - val_accuracy: 0.7353 - val_loss: 0.8642\n",
      "Epoch 19/19\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9673 - loss: 0.0947 - val_accuracy: 0.7157 - val_loss: 0.9681\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6904 - loss: 1.0560 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Definir número de classes\n",
    "num_classes = len(unique_types)\n",
    "\n",
    "def create_cnn_model(n_conv_layers=2, n_dense_layers=1, filters=32, kernel_size=3, pool_size=2, dense_units=64, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adicionar camadas convolucionais conforme definido por Optuna\n",
    "    for i in range(n_conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(X_train.shape[1], 1)))\n",
    "        else:\n",
    "            model.add(Conv1D(filters=filters * (2 ** i), kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Adicionar camadas densas conforme definido por Optuna\n",
    "    for _ in range(n_dense_layers):\n",
    "        model.add(Dense(dense_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Camada de saída\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Função objetivo para otimização do CNN com Optuna\n",
    "def objective_cnn(trial):\n",
    "    # Hiperparâmetros para CNN\n",
    "    n_conv_layers = trial.suggest_int('n_conv_layers', 1, 4)  \n",
    "    n_dense_layers = trial.suggest_int('n_dense_layers', 1, 3) \n",
    "    filters = trial.suggest_int('filters', 16, 64)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5) \n",
    "    pool_size = trial.suggest_int('pool_size', 2, 3) \n",
    "    dense_units = trial.suggest_int('dense_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
    "    epochs = trial.suggest_int('epochs', 5, 20)  \n",
    "\n",
    "    # Criação do modelo\n",
    "    model = create_cnn_model(n_conv_layers=n_conv_layers,\n",
    "                             n_dense_layers=n_dense_layers,\n",
    "                             filters=filters,\n",
    "                             kernel_size=kernel_size,\n",
    "                             pool_size=pool_size,\n",
    "                             dense_units=dense_units,\n",
    "                             dropout_rate=dropout_rate)\n",
    "\n",
    "    # Validação cruzada\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cv_scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        model.fit(X_fold_train, y_fold_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "        val_loss, val_accuracy = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        cv_scores.append(val_accuracy)\n",
    "    # Média da acurácia de validação cruzada\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    return mean_cv_accuracy\n",
    "\n",
    "# Estudo de otimização com Optuna para CNN\n",
    "study_cnn = optuna.create_study(direction='maximize')\n",
    "study_cnn.optimize(objective_cnn, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_cnn = study_cnn.best_params\n",
    "print(\"Melhores parâmetros para CNN:\", best_params_cnn)\n",
    "\n",
    "# Treinamento e avaliação do CNN com melhores parâmetros\n",
    "best_cnn_model = create_cnn_model(n_conv_layers=best_params_cnn['n_conv_layers'],\n",
    "                                  n_dense_layers=best_params_cnn['n_dense_layers'],\n",
    "                                  filters=best_params_cnn['filters'],\n",
    "                                  kernel_size=best_params_cnn['kernel_size'],\n",
    "                                  pool_size=best_params_cnn['pool_size'],\n",
    "                                  dense_units=best_params_cnn['dense_units'],\n",
    "                                  dropout_rate=best_params_cnn['dropout_rate'])\n",
    "\n",
    "# Treinamento do modelo com o melhor número de épocas\n",
    "history = best_cnn_model.fit(X_train, y_train, epochs=best_params_cnn['epochs'], batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação da CNN no conjunto de teste\n",
    "cnn_loss, cnn_accuracy = best_cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predições da CNN no conjunto de teste\n",
    "cnn_predictions = best_cnn_model.predict(X_test)\n",
    "cnn_predictions_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Classification report da CNN\n",
    "cnn_report = classification_report(y_test, cnn_predictions_classes, target_names=[str(cls) for cls in unique_types], zero_division=1, digits=2)\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, cnn_predictions_classes)\n",
    "\n",
    "# Acurácia de treinamento\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Acurácia da validação cruzada \n",
    "cv_mean_accuracy = study_cnn.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN - Acurácia (Treinamento): 0.9680\n",
      "CNN - Acurácia (Teste): 0.7157\n",
      "Acurácia média na validação cruzada (CNN): 0.9339\n",
      "\n",
      "Matriz de Confusão (CNN):\n",
      "[[22  2  1  9  0]\n",
      " [ 1  4  1  1  1]\n",
      " [ 2  0 35  2  1]\n",
      " [ 4  0  0  9  0]\n",
      " [ 1  0  1  2  3]]\n",
      "\n",
      "Classification Report (CNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LumA       0.73      0.65      0.69        34\n",
      "      Normal       0.67      0.50      0.57         8\n",
      "       Basal       0.92      0.88      0.90        40\n",
      "        LumB       0.39      0.69      0.50        13\n",
      "        Her2       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.72       102\n",
      "   macro avg       0.66      0.63      0.63       102\n",
      "weighted avg       0.75      0.72      0.72       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo resultados da CNN\n",
    "print(f'\\nCNN - Acurácia (Treinamento): {train_accuracy:.4f}')\n",
    "print(f'CNN - Acurácia (Teste): {cnn_accuracy:.4f}')\n",
    "print(f'Acurácia média na validação cruzada (CNN): {cv_mean_accuracy:.4f}')\n",
    "print(f'\\nMatriz de Confusão (CNN):\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report (CNN):\\n{cnn_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
