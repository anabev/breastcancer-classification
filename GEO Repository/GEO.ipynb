{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de Bibliotecas\n",
    "pip install pandas numpy matplotlib scikit-learn tensorflow keras seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de Bibliotecas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, SpatialDropout1D, SimpleRNN, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "df = pd.read_csv(\"C:/Users/ana_v/OneDrive/Documentos/Repositórios/GSE25066.csv\", low_memory=False)\n",
    "\n",
    "# Obtém os valores únicos na coluna 'Type'\n",
    "unique_types = df['type'].unique()\n",
    "\n",
    "# Cria um dicionário mapeando cada tipo único para um número\n",
    "type_to_numeric = {type_name: index for index, type_name in enumerate(unique_types)}\n",
    "\n",
    "# Aplica a substituição usando o método map\n",
    "df['type'] = df['type'].map(type_to_numeric)\n",
    "\n",
    "# Armazena a coluna 'type' para adicioná-la de volta posteriormente\n",
    "type_column = df['type']\n",
    "\n",
    "# Prepara o DataFrame para normalização (remover colunas desnecessárias)\n",
    "df_num = df.drop(columns=[\"sample\", \"type\"])\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicação do PCA\n",
    "pca = PCA(n_components=0.8)  \n",
    "pca.fit(dados_normalizados)\n",
    "dados_pca = pca.transform(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixar a seed para garantir a reprodutibilidade\n",
    "seed = 1\n",
    "\n",
    "# Divisão de treino e teste com random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados_pca, df['type'], test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.803921568627451\n",
      "Acurácia média na validação cruzada: 0.7894901960784313\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81        34\n",
      "           1       0.50      0.62      0.56         8\n",
      "           2       1.00      0.90      0.95        40\n",
      "           3       0.62      0.77      0.69        13\n",
      "           4       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.80       102\n",
      "   macro avg       0.70      0.73      0.71       102\n",
      "weighted avg       0.82      0.80      0.81       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[27  2  0  4  1]\n",
      " [ 1  5  0  0  2]\n",
      " [ 1  3 36  0  0]\n",
      " [ 3  0  0 10  0]\n",
      " [ 1  0  0  2  4]]\n"
     ]
    }
   ],
   "source": [
    "# Regressão Logística\n",
    "lr_model = LogisticRegression(max_iter=6500) \n",
    "lr_model.fit(X_train, y_train) \n",
    "lr_predictions_train = lr_model.predict(X_train)  \n",
    "lr_predictions_test = lr_model.predict(X_test) \n",
    "\n",
    "# Avaliação Regressão Logística\n",
    "lr_accuracy_train = accuracy_score(y_train, lr_predictions_train) \n",
    "lr_accuracy_test = accuracy_score(y_test, lr_predictions_test)  \n",
    "lr_report = classification_report(y_test, lr_predictions_test, zero_division=1) \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores = cross_val_score(lr_model, dados_pca, df['type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {lr_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores.mean()}')\n",
    "print(f'Classification Report:\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, lr_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.6862745098039216\n",
      "Acurácia média na validação cruzada: 0.6298823529411763\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.88      0.71        34\n",
      "           1       1.00      0.00      0.00         8\n",
      "           2       0.78      0.95      0.85        40\n",
      "           3       0.67      0.15      0.25        13\n",
      "           4       1.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.69       102\n",
      "   macro avg       0.81      0.40      0.36       102\n",
      "weighted avg       0.74      0.69      0.60       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[30  0  4  0  0]\n",
      " [ 6  0  2  0  0]\n",
      " [ 2  0 38  0  0]\n",
      " [ 9  0  2  2  0]\n",
      " [ 3  0  3  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)  \n",
    "rf_predictions_train = rf_model.predict(X_train)  \n",
    "rf_predictions_test = rf_model.predict(X_test) \n",
    "\n",
    "# Avaliação Random Forest\n",
    "rf_accuracy_train = accuracy_score(y_train, rf_predictions_train) \n",
    "rf_accuracy_test = accuracy_score(y_test, rf_predictions_test) \n",
    "rf_report = classification_report(y_test, rf_predictions_test, \n",
    "                                  zero_division=1) \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores_rf = cross_val_score(rf_model, dados_pca, df['type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {rf_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores_rf.mean()}')\n",
    "print(f'Classification Report:\\n{rf_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, rf_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.7647058823529411\n",
      "Acurácia média na validação cruzada: 0.7658431372549019\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81        34\n",
      "           1       0.50      0.62      0.56         8\n",
      "           2       1.00      0.90      0.95        40\n",
      "           3       0.62      0.77      0.69        13\n",
      "           4       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.80       102\n",
      "   macro avg       0.70      0.73      0.71       102\n",
      "weighted avg       0.82      0.80      0.81       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[32  0  0  2  0]\n",
      " [ 4  3  0  0  1]\n",
      " [ 2  0 37  0  1]\n",
      " [ 9  0  0  4  0]\n",
      " [ 2  0  1  2  2]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)  \n",
    "svm_predictions_train = svm_model.predict(X_train)  \n",
    "svm_predictions_test = svm_model.predict(X_test) \n",
    "\n",
    "# Avaliação SVM\n",
    "svm_accuracy_train = accuracy_score(y_train, svm_predictions_train)  \n",
    "svm_accuracy_test = accuracy_score(y_test, svm_predictions_test)  \n",
    "svm_report = classification_report(y_test, svm_predictions_test, zero_division=1)  \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores_svm = cross_val_score(svm_model, dados_pca, df['type'], cv=cv, \n",
    "                         scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {svm_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores_svm.mean()}')\n",
    "print(f'Classification Report:\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, svm_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Acurácia (Teste): 0.6862745098039216\n",
      "Acurácia média na validação cruzada (MLP): 0.6988235294117647\n",
      "Classification Report MLP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        34\n",
      "           1       0.60      0.38      0.46         8\n",
      "           2       0.84      0.90      0.87        40\n",
      "           3       0.33      0.31      0.32        13\n",
      "           4       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.69       102\n",
      "   macro avg       0.60      0.54      0.57       102\n",
      "weighted avg       0.68      0.69      0.68       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[24  1  2  7  0]\n",
      " [ 2  3  1  1  1]\n",
      " [ 3  1 36  0  0]\n",
      " [ 6  0  2  4  1]\n",
      " [ 2  0  2  0  3]]\n"
     ]
    }
   ],
   "source": [
    "# Criação e treinamento do MLP com 4 camadas ocultas\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 75, 50, 25), max_iter=500, random_state=seed)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de treino e teste\n",
    "mlp_predictions_train = mlp_model.predict(X_train)\n",
    "mlp_predictions_test = mlp_model.predict(X_test)\n",
    "\n",
    "# Avaliação MLP\n",
    "mlp_accuracy_train = accuracy_score(y_train, mlp_predictions_train)\n",
    "mlp_accuracy_test = accuracy_score(y_test, mlp_predictions_test)\n",
    "mlp_report = classification_report(y_test, mlp_predictions_test, zero_division=1)\n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "mlp_scores = cross_val_score(mlp_model, dados_pca, df['type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Exibindo resultados do MLP\n",
    "print(f'MLP - Acurácia (Teste): {mlp_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada (MLP): {mlp_scores.mean()}')\n",
    "print(f'Classification Report MLP:\\n{mlp_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, mlp_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.3169 - loss: 3.1022 - val_accuracy: 0.3039 - val_loss: 1.5400\n",
      "Epoch 2/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3407 - loss: 1.5188 - val_accuracy: 0.5196 - val_loss: 1.4403\n",
      "Epoch 3/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5345 - loss: 1.2927 - val_accuracy: 0.5196 - val_loss: 1.2385\n",
      "Epoch 4/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5731 - loss: 1.0846 - val_accuracy: 0.5392 - val_loss: 1.1537\n",
      "Epoch 5/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6216 - loss: 0.9843 - val_accuracy: 0.6176 - val_loss: 1.1171\n",
      "Epoch 6/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6770 - loss: 0.8087 - val_accuracy: 0.5980 - val_loss: 1.1156\n",
      "Epoch 7/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7114 - loss: 0.7211 - val_accuracy: 0.6078 - val_loss: 1.0662\n",
      "Epoch 8/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7476 - loss: 0.6378 - val_accuracy: 0.6471 - val_loss: 0.9960\n",
      "Epoch 9/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8311 - loss: 0.5348 - val_accuracy: 0.6471 - val_loss: 1.0197\n",
      "Epoch 10/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8075 - loss: 0.4665 - val_accuracy: 0.6078 - val_loss: 1.1095\n",
      "Epoch 11/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8433 - loss: 0.4038 - val_accuracy: 0.5784 - val_loss: 1.0617\n",
      "Epoch 12/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8843 - loss: 0.3715 - val_accuracy: 0.5784 - val_loss: 1.0739\n",
      "Epoch 13/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8906 - loss: 0.3065 - val_accuracy: 0.6078 - val_loss: 1.0665\n",
      "Epoch 14/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8743 - loss: 0.3208 - val_accuracy: 0.6569 - val_loss: 1.0920\n",
      "Epoch 15/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9037 - loss: 0.2511 - val_accuracy: 0.6569 - val_loss: 1.1761\n",
      "Epoch 16/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9251 - loss: 0.2365 - val_accuracy: 0.6275 - val_loss: 1.1495\n",
      "Epoch 17/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.2194 - val_accuracy: 0.6176 - val_loss: 1.2369\n",
      "Epoch 18/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9194 - loss: 0.2097 - val_accuracy: 0.6471 - val_loss: 1.1997\n",
      "Epoch 19/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.2490 - val_accuracy: 0.6078 - val_loss: 1.3142\n",
      "Epoch 20/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9183 - loss: 0.1998 - val_accuracy: 0.6275 - val_loss: 1.3014\n",
      "Epoch 21/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9297 - loss: 0.1964 - val_accuracy: 0.6275 - val_loss: 1.4222\n",
      "Epoch 22/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9289 - loss: 0.1771 - val_accuracy: 0.6471 - val_loss: 1.2772\n",
      "Epoch 23/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.1589 - val_accuracy: 0.6471 - val_loss: 1.2761\n",
      "Epoch 24/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9503 - loss: 0.1369 - val_accuracy: 0.6275 - val_loss: 1.3980\n",
      "Epoch 25/25\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9502 - loss: 0.1533 - val_accuracy: 0.6373 - val_loss: 1.4992\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6622 - loss: 1.4067 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "unique_types = df['type'].unique()\n",
    "num_classes = len(unique_types)\n",
    "target_names = [str(cls) for cls in unique_types]\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Função para criar o modelo CNN\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(64, 3, activation='relu'),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Validação cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cross_val_scores = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    model = create_cnn_model()\n",
    "    history = model.fit(X_fold_train, y_fold_train, epochs=25, batch_size=32, verbose=0, validation_data=(X_fold_val, y_fold_val))\n",
    "\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    cross_val_scores.append(val_accuracy)\n",
    "\n",
    "cross_val_mean = np.mean(cross_val_scores)\n",
    "cross_val_std = np.std(cross_val_scores)\n",
    "\n",
    "# Treinamento final da CNN\n",
    "model = create_cnn_model()\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação da CNN no conjunto de teste\n",
    "cnn_loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Exibindo resultados da CNN\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Predições da CNN no conjunto de teste\n",
    "cnn_predictions = model.predict(X_test)\n",
    "cnn_predictions_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Classification report da CNN\n",
    "cnn_report = classification_report(y_test, cnn_predictions_classes, target_names=target_names, zero_division=1, digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média na validação cruzada (CNN): 0.6328 ± 0.0605\n",
      "Acurácia (Teste): 0.6373\n",
      "Classification Report CNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.79      0.64        34\n",
      "           1       0.50      0.50      0.50         8\n",
      "           2       0.85      0.70      0.77        40\n",
      "           3       0.50      0.31      0.38        13\n",
      "           4       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.64       102\n",
      "   macro avg       0.61      0.52      0.54       102\n",
      "weighted avg       0.66      0.64      0.63       102\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[27  2  3  2  0]\n",
      " [ 2  4  1  0  1]\n",
      " [ 9  1 28  2  0]\n",
      " [ 8  0  1  4  0]\n",
      " [ 4  1  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print(f'Acurácia média na validação cruzada (CNN): {cross_val_mean:.4f} ± {cross_val_std:.4f}')\n",
    "print(f'Acurácia (Teste): {cnn_accuracy:.4f}')\n",
    "print(f'Classification Report CNN:\\n{cnn_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, cnn_predictions_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
