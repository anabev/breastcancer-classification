{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de Bibliotecas\n",
    "pip install pandas numpy matplotlib scikit-learn tensorflow keras seaborn optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importação de Bibliotecas\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, SpatialDropout1D, SimpleRNN, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "df = pd.read_csv(\"C:/Users/ana_v/OneDrive/Documentos/Repositórios/TCGA.csv\", low_memory=False)\n",
    "\n",
    "# Obtém os valores únicos na coluna 'Type'\n",
    "unique_types = df['Type'].unique()\n",
    "\n",
    "# Cria um dicionário mapeando cada tipo único para um número\n",
    "type_to_numeric = {type_name: index for index, type_name in enumerate(unique_types)}\n",
    "\n",
    "# Aplica a substituição usando o método map\n",
    "df['Type'] = df['Type'].map(type_to_numeric)\n",
    "\n",
    "# Armazena a coluna 'Type' para adicioná-la de volta posteriormente\n",
    "type_column = df['Type']\n",
    "\n",
    "# Prepara o DataFrame para normalização (remover colunas desnecessárias)\n",
    "df_num = df.drop(columns=[\"Sample\", \"Type\"])\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicação do PCA\n",
    "pca = PCA(n_components=0.8)  \n",
    "pca.fit(dados_normalizados)\n",
    "dados_pca = pca.transform(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 15:10:17,970] A new study created in memory with name: no-name-ed4c747e-f5a5-4919-859f-3e56089f8664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:18,329] Trial 0 finished with value: 0.7284684684684686 and parameters: {'svc_c': 0.008301451461243867, 'svc_kernel': 'linear'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:18,635] Trial 1 finished with value: 0.5214054054054055 and parameters: {'svc_c': 4.429657657076251e-05, 'svc_kernel': 'sigmoid'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:18,969] Trial 2 finished with value: 0.5214054054054055 and parameters: {'svc_c': 0.008597290483171273, 'svc_kernel': 'rbf'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:19,327] Trial 3 finished with value: 0.6363603603603604 and parameters: {'svc_c': 0.4934834261073345, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:19,828] Trial 4 finished with value: 0.7098558558558559 and parameters: {'svc_c': 4.029136499667933, 'svc_kernel': 'linear'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:20,014] Trial 5 finished with value: 0.7098738738738739 and parameters: {'svc_c': 18.291387257048378, 'svc_kernel': 'sigmoid'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:20,249] Trial 6 finished with value: 0.5214054054054055 and parameters: {'svc_c': 4.880090060376772e-05, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:20,530] Trial 7 finished with value: 0.5214054054054055 and parameters: {'svc_c': 0.0016166254707399778, 'svc_kernel': 'poly'}. Best is trial 0 with value: 0.7284684684684686.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:20,940] Trial 8 finished with value: 0.7766666666666667 and parameters: {'svc_c': 83.56561666138207, 'svc_kernel': 'rbf'}. Best is trial 8 with value: 0.7766666666666667.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:10:21,308] Trial 9 finished with value: 0.7205225225225226 and parameters: {'svc_c': 0.013653836035069419, 'svc_kernel': 'linear'}. Best is trial 8 with value: 0.7766666666666667.\n",
      "[I 2024-08-30 15:10:21,311] A new study created in memory with name: no-name-fe616675-e809-4618-b10e-a99101414620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para SVM: {'svc_c': 83.56561666138207, 'svc_kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 15:10:30,753] Trial 0 finished with value: 0.7165225225225226 and parameters: {'rf_n_estimators': 112, 'rf_max_depth': 39, 'rf_min_samples_split': 2}. Best is trial 0 with value: 0.7165225225225226.\n",
      "[I 2024-08-30 15:10:39,218] Trial 1 finished with value: 0.7125225225225226 and parameters: {'rf_n_estimators': 95, 'rf_max_depth': 16, 'rf_min_samples_split': 3}. Best is trial 0 with value: 0.7165225225225226.\n",
      "[I 2024-08-30 15:10:45,912] Trial 2 finished with value: 0.7231531531531532 and parameters: {'rf_n_estimators': 78, 'rf_max_depth': 24, 'rf_min_samples_split': 9}. Best is trial 2 with value: 0.7231531531531532.\n",
      "[I 2024-08-30 15:10:56,399] Trial 3 finished with value: 0.7192612612612612 and parameters: {'rf_n_estimators': 131, 'rf_max_depth': 27, 'rf_min_samples_split': 15}. Best is trial 2 with value: 0.7231531531531532.\n",
      "[I 2024-08-30 15:11:04,545] Trial 4 finished with value: 0.7165045045045044 and parameters: {'rf_n_estimators': 80, 'rf_max_depth': 46, 'rf_min_samples_split': 2}. Best is trial 2 with value: 0.7231531531531532.\n",
      "[I 2024-08-30 15:11:16,899] Trial 5 finished with value: 0.7205045045045047 and parameters: {'rf_n_estimators': 151, 'rf_max_depth': 27, 'rf_min_samples_split': 12}. Best is trial 2 with value: 0.7231531531531532.\n",
      "[I 2024-08-30 15:11:22,245] Trial 6 finished with value: 0.7110990990990992 and parameters: {'rf_n_estimators': 71, 'rf_max_depth': 18, 'rf_min_samples_split': 17}. Best is trial 2 with value: 0.7231531531531532.\n",
      "[I 2024-08-30 15:11:37,118] Trial 7 finished with value: 0.7258918918918918 and parameters: {'rf_n_estimators': 196, 'rf_max_depth': 22, 'rf_min_samples_split': 15}. Best is trial 7 with value: 0.7258918918918918.\n",
      "[I 2024-08-30 15:11:51,662] Trial 8 finished with value: 0.719171171171171 and parameters: {'rf_n_estimators': 182, 'rf_max_depth': 46, 'rf_min_samples_split': 3}. Best is trial 7 with value: 0.7258918918918918.\n",
      "[I 2024-08-30 15:11:55,635] Trial 9 finished with value: 0.7151351351351353 and parameters: {'rf_n_estimators': 55, 'rf_max_depth': 16, 'rf_min_samples_split': 18}. Best is trial 7 with value: 0.7258918918918918.\n",
      "[I 2024-08-30 15:11:55,636] A new study created in memory with name: no-name-aba995cc-a5ff-4d7c-b7ee-d8517f096b9d\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Random Forest: {'rf_n_estimators': 196, 'rf_max_depth': 22, 'rf_min_samples_split': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 15:11:56,848] Trial 0 finished with value: 0.7793153153153154 and parameters: {'lr_c': 0.008301451461243867, 'lr_solver': 'newton-cg'}. Best is trial 0 with value: 0.7793153153153154.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:12:37,407] Trial 1 finished with value: 0.7887387387387388 and parameters: {'lr_c': 4.429657657076251e-05, 'lr_solver': 'saga'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:12:39,814] Trial 2 finished with value: 0.7485045045045046 and parameters: {'lr_c': 0.008597290483171273, 'lr_solver': 'liblinear'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:12:43,129] Trial 3 finished with value: 0.7272252252252251 and parameters: {'lr_c': 0.4934834261073345, 'lr_solver': 'lbfgs'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:12:45,863] Trial 4 finished with value: 0.7124684684684685 and parameters: {'lr_c': 4.029136499667933, 'lr_solver': 'newton-cg'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:14:05,924] Trial 5 finished with value: 0.7271891891891892 and parameters: {'lr_c': 18.291387257048378, 'lr_solver': 'saga'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:14:06,417] Trial 6 finished with value: 0.7767387387387388 and parameters: {'lr_c': 4.880090060376772e-05, 'lr_solver': 'lbfgs'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:14:07,728] Trial 7 finished with value: 0.782 and parameters: {'lr_c': 0.0016166254707399778, 'lr_solver': 'lbfgs'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:14:33,192] Trial 8 finished with value: 0.6790090090090091 and parameters: {'lr_c': 83.56561666138207, 'lr_solver': 'liblinear'}. Best is trial 1 with value: 0.7887387387387388.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\376960319.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
      "[I 2024-08-30 15:14:34,531] Trial 9 finished with value: 0.7686306306306306 and parameters: {'lr_c': 0.013653836035069419, 'lr_solver': 'newton-cg'}. Best is trial 1 with value: 0.7887387387387388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Regressão Logística: {'lr_c': 4.429657657076251e-05, 'lr_solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "# Fixar a seed para garantir a reprodutibilidade\n",
    "seed = 1\n",
    "\n",
    "# Divisão de treino e teste com random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados_pca, df['Type'], test_size=0.2, random_state=seed)\n",
    "\n",
    "# Função objetivo para otimização do SVM\n",
    "def objective_svm(trial):\n",
    "    svc_c = trial.suggest_loguniform('svc_c', 1e-5, 1e2)\n",
    "    svc_kernel = trial.suggest_categorical('svc_kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    \n",
    "    model_svm = SVC(C=svc_c, kernel=svc_kernel, random_state=seed)\n",
    "    score = cross_val_score(model_svm, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Função objetivo para otimização do Random Forest\n",
    "def objective_rf(trial):\n",
    "    rf_n_estimators = trial.suggest_int('rf_n_estimators', 50, 200)\n",
    "    rf_max_depth = trial.suggest_int('rf_max_depth', 10, 50)\n",
    "    rf_min_samples_split = trial.suggest_int('rf_min_samples_split', 2, 20)\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=rf_n_estimators, max_depth=rf_max_depth,\n",
    "                                      min_samples_split=rf_min_samples_split, random_state=seed)\n",
    "    score = cross_val_score(model_rf, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Função objetivo para otimização da Regressão Logística\n",
    "def objective_lr(trial):\n",
    "    lr_c = trial.suggest_loguniform('lr_c', 1e-5, 1e2)\n",
    "    lr_solver = trial.suggest_categorical('lr_solver', ['newton-cg', 'lbfgs', 'liblinear', 'saga'])\n",
    "    \n",
    "    model_lr = LogisticRegression(C=lr_c, solver=lr_solver, max_iter=10000, random_state=seed)\n",
    "    score = cross_val_score(model_lr, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Estudo e otimização com Optuna para SVM\n",
    "study_svm = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_svm.optimize(objective_svm, n_trials=10)\n",
    "best_params_svm = study_svm.best_params\n",
    "print(\"Melhores parâmetros para SVM:\", best_params_svm)\n",
    "\n",
    "# Estudo e otimização com Optuna para Random Forest\n",
    "study_rf = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_rf.optimize(objective_rf, n_trials=10)\n",
    "best_params_rf = study_rf.best_params\n",
    "print(\"Melhores parâmetros para Random Forest:\", best_params_rf)\n",
    "\n",
    "# Estudo e otimização com Optuna para Regressão Logística\n",
    "study_lr = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_lr.optimize(objective_lr, n_trials=10)\n",
    "best_params_lr = study_lr.best_params\n",
    "print(\"Melhores parâmetros para Regressão Logística:\", best_params_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Acurácia (Teste): 0.7754010695187166\n",
      "Acurácia média na validação cruzada: 0.7766666666666667\n",
      "\n",
      "Classification Report (SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88        90\n",
      "           1       0.64      0.61      0.62        41\n",
      "           2       0.85      0.90      0.88        31\n",
      "           3       0.70      0.33      0.45        21\n",
      "           4       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.67      0.61      0.62       187\n",
      "weighted avg       0.76      0.78      0.76       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[84  4  1  1  0]\n",
      " [13 25  1  2  0]\n",
      " [ 1  2 28  0  0]\n",
      " [ 1  8  3  7  2]\n",
      " [ 3  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo SVM com os melhores parâmetros\n",
    "best_model_svm = SVC(C=best_params_svm['svc_c'], kernel=best_params_svm['svc_kernel'], random_state=seed)\n",
    "best_model_svm.fit(X_train, y_train)\n",
    "svm_predictions_train = best_model_svm.predict(X_train)\n",
    "svm_predictions_test = best_model_svm.predict(X_test)\n",
    "\n",
    "# Avaliação SVM\n",
    "svm_accuracy_train = accuracy_score(y_train, svm_predictions_train)\n",
    "svm_accuracy_test = accuracy_score(y_test, svm_predictions_test)\n",
    "svm_report = classification_report(y_test, svm_predictions_test, zero_division=1)\n",
    "\n",
    "# Resultados\n",
    "print(f'SVM - Acurácia (Teste): {svm_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_svm, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (SVM):\\n{svm_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, svm_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Acurácia (Teste): 0.6951871657754011\n",
      "Acurácia média na validação cruzada: 0.7258918918918918\n",
      "\n",
      "Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79        90\n",
      "           1       0.59      0.46      0.52        41\n",
      "           2       0.80      0.90      0.85        31\n",
      "           3       1.00      0.00      0.00        21\n",
      "           4       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.70       187\n",
      "   macro avg       0.82      0.46      0.43       187\n",
      "weighted avg       0.73      0.70      0.64       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[83  7  0  0  0]\n",
      " [21 19  1  0  0]\n",
      " [ 2  1 28  0  0]\n",
      " [10  5  6  0  0]\n",
      " [ 4  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo Random Forest com os melhores parâmetros\n",
    "best_model_rf = RandomForestClassifier(\n",
    "    n_estimators=best_params_rf['rf_n_estimators'],\n",
    "    max_depth=best_params_rf['rf_max_depth'],\n",
    "    min_samples_split=best_params_rf['rf_min_samples_split'],\n",
    "    random_state=seed\n",
    ")\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "rf_predictions_train = best_model_rf.predict(X_train)\n",
    "rf_predictions_test = best_model_rf.predict(X_test)\n",
    "\n",
    "# Avaliação Random Forest\n",
    "rf_accuracy_train = accuracy_score(y_train, rf_predictions_train)\n",
    "rf_accuracy_test = accuracy_score(y_test, rf_predictions_test)\n",
    "rf_report = classification_report(y_test, rf_predictions_test, zero_division=1)\n",
    "\n",
    "print(f'Random Forest - Acurácia (Teste): {rf_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_rf, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (Random Forest):\\n{rf_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, rf_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.7807486631016043\n",
      "Acurácia média na validação cruzada: 0.7887387387387388\n",
      "\n",
      "Classification Report (Regressão Logística):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84        90\n",
      "           1       0.80      0.49      0.61        41\n",
      "           2       0.85      0.94      0.89        31\n",
      "           3       1.00      0.43      0.60        21\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.78       187\n",
      "   macro avg       0.68      0.57      0.59       187\n",
      "weighted avg       0.79      0.78      0.75       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[88  1  1  0  0]\n",
      " [20 20  1  0  0]\n",
      " [ 2  0 29  0  0]\n",
      " [ 6  4  2  9  0]\n",
      " [ 3  0  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Treinar e avaliar o modelo Regressão Logística com os melhores parâmetros\n",
    "best_model_lr = LogisticRegression(\n",
    "    C=best_params_lr['lr_c'],\n",
    "    solver=best_params_lr['lr_solver'],\n",
    "    max_iter=10000,\n",
    "    random_state=seed\n",
    ")\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "lr_predictions_train = best_model_lr.predict(X_train)\n",
    "lr_predictions_test = best_model_lr.predict(X_test)\n",
    "\n",
    "# Avaliação Regressão Logística\n",
    "lr_accuracy_train = accuracy_score(y_train, lr_predictions_train)\n",
    "lr_accuracy_test = accuracy_score(y_test, lr_predictions_test)\n",
    "lr_report = classification_report(y_test, lr_predictions_test)\n",
    "\n",
    "print(f'Regressão Logística - Acurácia (Teste): {lr_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {cross_val_score(best_model_lr, X_train, y_train, cv=10).mean()}')\n",
    "print(f'\\nClassification Report (Regressão Logística):\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, lr_predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 15:16:12,250] A new study created in memory with name: no-name-c245d3ea-779f-4dcd-bd16-58aaffb300c4\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:16:16,087] Trial 0 finished with value: 0.5215391498881432 and parameters: {'n_layers': 4, 'n_units_l0': 115, 'n_units_l1': 25, 'n_units_l2': 63, 'n_units_l3': 43, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 0.00047509237210306113, 'learning_rate_init': 0.011367330868956235}. Best is trial 0 with value: 0.5215391498881432.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-30 15:16:42,904] Trial 1 finished with value: 0.7486800894854586 and parameters: {'n_layers': 3, 'n_units_l0': 135, 'n_units_l1': 28, 'n_units_l2': 109, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0746528346269155, 'learning_rate_init': 0.0008715103205978142}. Best is trial 1 with value: 0.7486800894854586.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:16:50,071] Trial 2 finished with value: 0.7260134228187919 and parameters: {'n_layers': 5, 'n_units_l0': 135, 'n_units_l1': 137, 'n_units_l2': 35, 'n_units_l3': 29, 'n_units_l4': 46, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.005854751355295724, 'learning_rate_init': 0.0008841926348917736}. Best is trial 1 with value: 0.7486800894854586.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:17:40,494] Trial 3 finished with value: 0.7219686800894854 and parameters: {'n_layers': 5, 'n_units_l0': 130, 'n_units_l1': 27, 'n_units_l2': 119, 'n_units_l3': 149, 'n_units_l4': 119, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.0001494364677378836, 'learning_rate_init': 0.0007300053042915264}. Best is trial 1 with value: 0.7486800894854586.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-08-30 15:18:00,342] Trial 4 finished with value: 0.7594004474272931 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'n_units_l1': 110, 'activation': 'logistic', 'solver': 'sgd', 'alpha': 3.862907418494322e-05, 'learning_rate_init': 0.005860256303804338}. Best is trial 4 with value: 0.7594004474272931.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:18:23,570] Trial 5 finished with value: 0.6804742729306488 and parameters: {'n_layers': 5, 'n_units_l0': 37, 'n_units_l1': 77, 'n_units_l2': 112, 'n_units_l3': 77, 'n_units_l4': 31, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.04107784588077006, 'learning_rate_init': 0.0002584783141380735}. Best is trial 4 with value: 0.7594004474272931.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:18:31,229] Trial 6 finished with value: 0.7607606263982103 and parameters: {'n_layers': 2, 'n_units_l0': 126, 'n_units_l1': 75, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.034136922393519724, 'learning_rate_init': 0.007430475750099704}. Best is trial 6 with value: 0.7607606263982103.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:18:36,781] Trial 7 finished with value: 0.7047069351230425 and parameters: {'n_layers': 5, 'n_units_l0': 68, 'n_units_l1': 59, 'n_units_l2': 137, 'n_units_l3': 78, 'n_units_l4': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.002058535957997779, 'learning_rate_init': 0.0016765264451568493}. Best is trial 6 with value: 0.7607606263982103.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:18:48,986] Trial 8 finished with value: 0.7714362416107383 and parameters: {'n_layers': 3, 'n_units_l0': 138, 'n_units_l1': 97, 'n_units_l2': 25, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.04306660168805714, 'learning_rate_init': 0.007414474013266335}. Best is trial 8 with value: 0.7714362416107383.\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2410050370.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
      "[I 2024-08-30 15:18:56,471] Trial 9 finished with value: 0.7300223713646532 and parameters: {'n_layers': 2, 'n_units_l0': 142, 'n_units_l1': 112, 'activation': 'relu', 'solver': 'adam', 'alpha': 1.8365412649690993e-05, 'learning_rate_init': 0.018466694211779083}. Best is trial 8 with value: 0.7714362416107383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para MLP: {'n_layers': 3, 'n_units_l0': 138, 'n_units_l1': 97, 'n_units_l2': 25, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.04306660168805714, 'learning_rate_init': 0.007414474013266335}\n"
     ]
    }
   ],
   "source": [
    "# Função objetivo para otimização do MLP\n",
    "def objective_mlp(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 6)\n",
    "    hidden_layer_sizes = [trial.suggest_int(f'n_units_l{i}', 25, 150) for i in range(n_layers)]\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n",
    "    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e-1)\n",
    "    learning_rate_init = trial.suggest_loguniform('learning_rate_init', 1e-4, 1e-1)\n",
    "    \n",
    "    # Criar e treinar o modelo\n",
    "    model = MLPClassifier(hidden_layer_sizes=tuple(hidden_layer_sizes), activation=activation,\n",
    "                          solver=solver, alpha=alpha, learning_rate_init=learning_rate_init,\n",
    "                          max_iter=500, random_state=seed)\n",
    "    \n",
    "    # Validação cruzada\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Estudo de otimização com Optuna para MLP\n",
    "study_mlp = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study_mlp.optimize(objective_mlp, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_mlp = study_mlp.best_params\n",
    "print(\"Melhores parâmetros para MLP:\", best_params_mlp)\n",
    "\n",
    "# Treinamento e avaliação do MLP com os melhores parâmetros\n",
    "best_mlp_model = MLPClassifier(hidden_layer_sizes=tuple(best_params_mlp[f'n_units_l{i}'] for i in range(best_params_mlp['n_layers'])),\n",
    "                               activation=best_params_mlp['activation'],\n",
    "                               solver=best_params_mlp['solver'],\n",
    "                               alpha=best_params_mlp['alpha'],\n",
    "                               learning_rate_init=best_params_mlp['learning_rate_init'],\n",
    "                               max_iter=500, random_state=seed)\n",
    "best_mlp_model.fit(X_train, y_train)\n",
    "mlp_predictions_train = best_mlp_model.predict(X_train)\n",
    "mlp_predictions_test = best_mlp_model.predict(X_test)\n",
    "\n",
    "# Avaliação do modelo\n",
    "mlp_accuracy_train = accuracy_score(y_train, mlp_predictions_train)\n",
    "mlp_accuracy_test = accuracy_score(y_test, mlp_predictions_test)\n",
    "mlp_report = classification_report(y_test, mlp_predictions_test, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados do MLP:\n",
      "Matriz de Confusão:\n",
      " [[82  4  0  2  2]\n",
      " [13 26  0  2  0]\n",
      " [ 0  1 27  1  2]\n",
      " [ 0  7  2 11  1]\n",
      " [ 2  0  0  0  2]]\n",
      "Acurácia (Teste): 0.7914438502673797\n",
      "Acurácia média na validação cruzada (MLP): 0.7794\n",
      "\n",
      "Classification Report (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88        90\n",
      "           1       0.68      0.63      0.66        41\n",
      "           2       0.93      0.87      0.90        31\n",
      "           3       0.69      0.52      0.59        21\n",
      "           4       0.29      0.50      0.36         4\n",
      "\n",
      "    accuracy                           0.79       187\n",
      "   macro avg       0.69      0.69      0.68       187\n",
      "weighted avg       0.79      0.79      0.79       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliação para MLP\n",
    "print(\"\\nResultados do MLP:\")\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, mlp_predictions_test))\n",
    "print(\"Acurácia (Teste):\", accuracy_score(y_test, mlp_predictions_test))\n",
    "\n",
    "# Acurácia média na validação cruzada\n",
    "cv_mean_score = cross_val_score(best_mlp_model, X_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "print(f'Acurácia média na validação cruzada (MLP): {cv_mean_score:.4f}')\n",
    "\n",
    "# Classification Report\n",
    "print(f'\\nClassification Report (MLP):\\n{mlp_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 15:19:36,936] A new study created in memory with name: no-name-79f0305a-315e-4e20-ad45-4a76b1b1c0b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ana_v\\AppData\\Local\\Temp\\ipykernel_17568\\2481448741.py:41: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "[I 2024-08-30 15:19:47,009] Trial 0 finished with value: 0.843874716758728 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 3, 'filters': 31, 'kernel_size': 5, 'pool_size': 3, 'dense_units': 51, 'dropout_rate': 0.24977909768738082, 'epochs': 11}. Best is trial 0 with value: 0.843874716758728.\n",
      "[I 2024-08-30 15:19:56,621] Trial 1 finished with value: 0.9079731583595276 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 1, 'filters': 35, 'kernel_size': 2, 'pool_size': 2, 'dense_units': 76, 'dropout_rate': 0.32821271257575513, 'epochs': 12}. Best is trial 1 with value: 0.9079731583595276.\n",
      "[I 2024-08-30 15:20:10,275] Trial 2 finished with value: 0.8238031387329101 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 2, 'filters': 45, 'kernel_size': 5, 'pool_size': 2, 'dense_units': 56, 'dropout_rate': 0.4925874236066337, 'epochs': 13}. Best is trial 1 with value: 0.9079731583595276.\n",
      "[I 2024-08-30 15:20:18,675] Trial 3 finished with value: 0.726201343536377 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 3, 'filters': 52, 'kernel_size': 2, 'pool_size': 3, 'dense_units': 33, 'dropout_rate': 0.22881774172348307, 'epochs': 10}. Best is trial 1 with value: 0.9079731583595276.\n",
      "[I 2024-08-30 15:20:24,795] Trial 4 finished with value: 0.8772259473800659 and parameters: {'n_conv_layers': 2, 'n_dense_layers': 1, 'filters': 29, 'kernel_size': 5, 'pool_size': 2, 'dense_units': 56, 'dropout_rate': 0.44104550923219576, 'epochs': 8}. Best is trial 1 with value: 0.9079731583595276.\n",
      "[I 2024-08-30 15:20:41,883] Trial 5 finished with value: 0.9239642143249511 and parameters: {'n_conv_layers': 4, 'n_dense_layers': 1, 'filters': 31, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 125, 'dropout_rate': 0.47179860434737037, 'epochs': 17}. Best is trial 5 with value: 0.9239642143249511.\n",
      "[I 2024-08-30 15:20:49,012] Trial 6 finished with value: 0.8504519104957581 and parameters: {'n_conv_layers': 1, 'n_dense_layers': 3, 'filters': 41, 'kernel_size': 4, 'pool_size': 2, 'dense_units': 106, 'dropout_rate': 0.25048146219509837, 'epochs': 10}. Best is trial 5 with value: 0.9239642143249511.\n",
      "[I 2024-08-30 15:21:00,933] Trial 7 finished with value: 0.8866129755973816 and parameters: {'n_conv_layers': 4, 'n_dense_layers': 3, 'filters': 18, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 90, 'dropout_rate': 0.28882554910849745, 'epochs': 13}. Best is trial 5 with value: 0.9239642143249511.\n",
      "[I 2024-08-30 15:21:12,659] Trial 8 finished with value: 0.9159731507301331 and parameters: {'n_conv_layers': 2, 'n_dense_layers': 1, 'filters': 43, 'kernel_size': 5, 'pool_size': 2, 'dense_units': 86, 'dropout_rate': 0.32934817674009487, 'epochs': 15}. Best is trial 5 with value: 0.9239642143249511.\n",
      "[I 2024-08-30 15:21:21,308] Trial 9 finished with value: 0.7649753808975219 and parameters: {'n_conv_layers': 1, 'n_dense_layers': 3, 'filters': 30, 'kernel_size': 5, 'pool_size': 2, 'dense_units': 82, 'dropout_rate': 0.3971087356784254, 'epochs': 13}. Best is trial 5 with value: 0.9239642143249511.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para CNN: {'n_conv_layers': 4, 'n_dense_layers': 1, 'filters': 31, 'kernel_size': 3, 'pool_size': 2, 'dense_units': 125, 'dropout_rate': 0.47179860434737037, 'epochs': 17}\n",
      "Epoch 1/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4516 - loss: 1.6647 - val_accuracy: 0.5722 - val_loss: 1.2224\n",
      "Epoch 2/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6171 - loss: 1.1361 - val_accuracy: 0.6203 - val_loss: 0.9917\n",
      "Epoch 3/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7034 - loss: 0.8681 - val_accuracy: 0.6203 - val_loss: 0.9819\n",
      "Epoch 4/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7100 - loss: 0.7477 - val_accuracy: 0.6791 - val_loss: 0.7596\n",
      "Epoch 5/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7718 - loss: 0.6122 - val_accuracy: 0.6684 - val_loss: 0.9167\n",
      "Epoch 6/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8037 - loss: 0.5187 - val_accuracy: 0.7005 - val_loss: 0.7943\n",
      "Epoch 7/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8369 - loss: 0.4595 - val_accuracy: 0.7273 - val_loss: 0.8617\n",
      "Epoch 8/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8681 - loss: 0.3545 - val_accuracy: 0.7112 - val_loss: 0.7888\n",
      "Epoch 9/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9105 - loss: 0.2828 - val_accuracy: 0.6898 - val_loss: 1.0700\n",
      "Epoch 10/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8862 - loss: 0.3005 - val_accuracy: 0.7005 - val_loss: 0.9335\n",
      "Epoch 11/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9032 - loss: 0.2845 - val_accuracy: 0.7219 - val_loss: 1.0450\n",
      "Epoch 12/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2947 - val_accuracy: 0.7059 - val_loss: 0.9339\n",
      "Epoch 13/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9364 - loss: 0.2127 - val_accuracy: 0.6738 - val_loss: 1.4485\n",
      "Epoch 14/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9419 - loss: 0.1738 - val_accuracy: 0.7059 - val_loss: 1.2749\n",
      "Epoch 15/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9593 - loss: 0.1161 - val_accuracy: 0.6845 - val_loss: 1.3847\n",
      "Epoch 16/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9538 - loss: 0.1061 - val_accuracy: 0.6684 - val_loss: 1.2780\n",
      "Epoch 17/17\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9485 - loss: 0.1529 - val_accuracy: 0.7005 - val_loss: 1.3459\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7151 - loss: 1.2195 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Definir número de classes\n",
    "num_classes = len(unique_types)\n",
    "\n",
    "def create_cnn_model(n_conv_layers=2, n_dense_layers=1, filters=32, kernel_size=3, pool_size=2, dense_units=64, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adicionar camadas convolucionais conforme definido por Optuna\n",
    "    for i in range(n_conv_layers):\n",
    "        if i == 0:\n",
    "            model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(X_train.shape[1], 1)))\n",
    "        else:\n",
    "            model.add(Conv1D(filters=filters * (2 ** i), kernel_size=kernel_size, activation='relu', padding='same'))\n",
    "        model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Adicionar camadas densas conforme definido por Optuna\n",
    "    for _ in range(n_dense_layers):\n",
    "        model.add(Dense(dense_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Camada de saída\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Função objetivo para otimização do CNN com Optuna\n",
    "def objective_cnn(trial):\n",
    "    # Hiperparâmetros para CNN\n",
    "    n_conv_layers = trial.suggest_int('n_conv_layers', 1, 4)  \n",
    "    n_dense_layers = trial.suggest_int('n_dense_layers', 1, 3) \n",
    "    filters = trial.suggest_int('filters', 16, 64)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 2, 5) \n",
    "    pool_size = trial.suggest_int('pool_size', 2, 3) \n",
    "    dense_units = trial.suggest_int('dense_units', 32, 128)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.5)\n",
    "    epochs = trial.suggest_int('epochs', 5, 20)  \n",
    "\n",
    "    # Criação do modelo\n",
    "    model = create_cnn_model(n_conv_layers=n_conv_layers,\n",
    "                             n_dense_layers=n_dense_layers,\n",
    "                             filters=filters,\n",
    "                             kernel_size=kernel_size,\n",
    "                             pool_size=pool_size,\n",
    "                             dense_units=dense_units,\n",
    "                             dropout_rate=dropout_rate)\n",
    "\n",
    "    # Validação cruzada\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cv_scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        model.fit(X_fold_train, y_fold_train, epochs=epochs, batch_size=32, verbose=0)\n",
    "        val_loss, val_accuracy = model.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "        cv_scores.append(val_accuracy)\n",
    "    # Média da acurácia de validação cruzada\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    return mean_cv_accuracy\n",
    "\n",
    "# Estudo de otimização com Optuna para CNN\n",
    "study_cnn = optuna.create_study(direction='maximize')\n",
    "study_cnn.optimize(objective_cnn, n_trials=10)\n",
    "\n",
    "# Melhores parâmetros\n",
    "best_params_cnn = study_cnn.best_params\n",
    "print(\"Melhores parâmetros para CNN:\", best_params_cnn)\n",
    "\n",
    "# Treinamento e avaliação do CNN com melhores parâmetros\n",
    "best_cnn_model = create_cnn_model(n_conv_layers=best_params_cnn['n_conv_layers'],\n",
    "                                  n_dense_layers=best_params_cnn['n_dense_layers'],\n",
    "                                  filters=best_params_cnn['filters'],\n",
    "                                  kernel_size=best_params_cnn['kernel_size'],\n",
    "                                  pool_size=best_params_cnn['pool_size'],\n",
    "                                  dense_units=best_params_cnn['dense_units'],\n",
    "                                  dropout_rate=best_params_cnn['dropout_rate'])\n",
    "\n",
    "# Treinamento do modelo com o melhor número de épocas\n",
    "history = best_cnn_model.fit(X_train, y_train, epochs=best_params_cnn['epochs'], batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação da CNN no conjunto de teste\n",
    "cnn_loss, cnn_accuracy = best_cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predições da CNN no conjunto de teste\n",
    "cnn_predictions = best_cnn_model.predict(X_test)\n",
    "cnn_predictions_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Classification report da CNN\n",
    "cnn_report = classification_report(y_test, cnn_predictions_classes, target_names=[str(cls) for cls in unique_types], zero_division=1, digits=2)\n",
    "\n",
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, cnn_predictions_classes)\n",
    "\n",
    "# Acurácia de treinamento\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "\n",
    "# Acurácia da validação cruzada \n",
    "cv_mean_accuracy = study_cnn.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN - Acurácia (Treinamento): 0.9492\n",
      "CNN - Acurácia (Teste): 0.7005\n",
      "Acurácia média na validação cruzada (CNN): 0.9240\n",
      "\n",
      "Matriz de Confusão (CNN):\n",
      "[[78 11  0  1  0]\n",
      " [17 20  1  2  1]\n",
      " [ 2  2 26  0  1]\n",
      " [ 6  7  2  6  0]\n",
      " [ 2  0  0  1  1]]\n",
      "\n",
      "Classification Report (CNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        LumA       0.74      0.87      0.80        90\n",
      "        LumB       0.50      0.49      0.49        41\n",
      "       Basal       0.90      0.84      0.87        31\n",
      "        Her2       0.60      0.29      0.39        21\n",
      "      Normal       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.70       187\n",
      "   macro avg       0.61      0.55      0.57       187\n",
      "weighted avg       0.69      0.70      0.69       187\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo resultados da CNN\n",
    "print(f'\\nCNN - Acurácia (Treinamento): {train_accuracy:.4f}')\n",
    "print(f'CNN - Acurácia (Teste): {cnn_accuracy:.4f}')\n",
    "print(f'Acurácia média na validação cruzada (CNN): {cv_mean_accuracy:.4f}')\n",
    "print(f'\\nMatriz de Confusão (CNN):\\n{conf_matrix}')\n",
    "print(f'\\nClassification Report (CNN):\\n{cnn_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
