{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de Bibliotecas\n",
    "pip install pandas numpy matplotlib scikit-learn tensorflow keras seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de Bibliotecas\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout, SpatialDropout1D, SimpleRNN, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "df = pd.read_csv(\"C:/Users/ana_v/OneDrive/Documentos/Repositórios/TCGA.csv\", low_memory=False)\n",
    "\n",
    "# Obtém os valores únicos na coluna 'Type'\n",
    "unique_types = df['Type'].unique()\n",
    "\n",
    "# Cria um dicionário mapeando cada tipo único para um número\n",
    "type_to_numeric = {type_name: index for index, type_name in enumerate(unique_types)}\n",
    "\n",
    "# Aplica a substituição usando o método map\n",
    "df['Type'] = df['Type'].map(type_to_numeric)\n",
    "\n",
    "# Armazena a coluna 'Type' para adicioná-la de volta posteriormente\n",
    "type_column = df['Type']\n",
    "\n",
    "# Prepara o DataFrame para normalização (remover colunas desnecessárias)\n",
    "df_num = df.drop(columns=[\"Sample\", \"Type\"])\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicação do PCA\n",
    "pca = PCA(n_components=0.8)  \n",
    "pca.fit(dados_normalizados)\n",
    "dados_pca = pca.transform(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixar a seed para garantir a reprodutibilidade\n",
    "seed = 1\n",
    "\n",
    "# Divisão de treino e teste com random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dados_pca, df['Type'], test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.7165775401069518\n",
      "Acurácia média na validação cruzada: 0.7346945778997942\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        90\n",
      "           1       0.55      0.66      0.60        41\n",
      "           2       0.80      0.77      0.79        31\n",
      "           3       0.78      0.33      0.47        21\n",
      "           4       0.18      0.50      0.27         4\n",
      "\n",
      "    accuracy                           0.72       187\n",
      "   macro avg       0.63      0.62      0.59       187\n",
      "weighted avg       0.75      0.72      0.72       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[74  9  3  1  3]\n",
      " [ 9 27  2  1  2]\n",
      " [ 2  4 24  0  1]\n",
      " [ 1  9  1  7  3]\n",
      " [ 2  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "# Regressão Logística\n",
    "lr_model = LogisticRegression(max_iter=6500) \n",
    "lr_model.fit(X_train, y_train) \n",
    "lr_predictions_train = lr_model.predict(X_train)  \n",
    "lr_predictions_test = lr_model.predict(X_test) \n",
    "\n",
    "# Avaliação Regressão Logística\n",
    "lr_accuracy_train = accuracy_score(y_train, lr_predictions_train) \n",
    "lr_accuracy_test = accuracy_score(y_test, lr_predictions_test)  \n",
    "lr_report = classification_report(y_test, lr_predictions_test, zero_division=1) \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores = cross_val_score(lr_model, dados_pca, df['Type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {lr_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores.mean()}')\n",
    "print(f'Classification Report:\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, lr_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.7700534759358288\n",
      "Acurácia média na validação cruzada: 0.7925303134294212\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        90\n",
      "           1       0.55      0.66      0.60        41\n",
      "           2       0.80      0.77      0.79        31\n",
      "           3       0.78      0.33      0.47        21\n",
      "           4       0.18      0.50      0.27         4\n",
      "\n",
      "    accuracy                           0.72       187\n",
      "   macro avg       0.63      0.62      0.59       187\n",
      "weighted avg       0.75      0.72      0.72       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[88  2  0  0  0]\n",
      " [18 20  1  2  0]\n",
      " [ 2  0 29  0  0]\n",
      " [ 5  5  4  7  0]\n",
      " [ 4  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)  \n",
    "svm_predictions_train = svm_model.predict(X_train)  \n",
    "svm_predictions_test = svm_model.predict(X_test) \n",
    "\n",
    "# Avaliação SVM\n",
    "svm_accuracy_train = accuracy_score(y_train, svm_predictions_train)  \n",
    "svm_accuracy_test = accuracy_score(y_test, svm_predictions_test)  \n",
    "svm_report = classification_report(y_test, svm_predictions_test, zero_division=1)  \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores_svm = cross_val_score(svm_model, dados_pca, df['Type'], cv=cv, \n",
    "                         scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {svm_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores_svm.mean()}')\n",
    "print(f'Classification Report:\\n{lr_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, svm_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão Logística - Acurácia (Teste): 0.7112299465240641\n",
      "Acurácia média na validação cruzada: 0.7294326241134752\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81        90\n",
      "           1       0.61      0.49      0.54        41\n",
      "           2       0.80      0.90      0.85        31\n",
      "           3       1.00      0.05      0.09        21\n",
      "           4       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.71       187\n",
      "   macro avg       0.82      0.47      0.46       187\n",
      "weighted avg       0.74      0.71      0.66       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[84  6  0  0  0]\n",
      " [19 20  2  0  0]\n",
      " [ 2  1 28  0  0]\n",
      " [10  6  4  1  0]\n",
      " [ 3  0  1  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)  \n",
    "rf_predictions_train = rf_model.predict(X_train)  \n",
    "rf_predictions_test = rf_model.predict(X_test) \n",
    "\n",
    "# Avaliação Random Forest\n",
    "rf_accuracy_train = accuracy_score(y_train, rf_predictions_train) \n",
    "rf_accuracy_test = accuracy_score(y_test, rf_predictions_test) \n",
    "rf_report = classification_report(y_test, rf_predictions_test, \n",
    "                                  zero_division=1) \n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "scores_rf = cross_val_score(rf_model, dados_pca, df['Type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Imprimir os resultados\n",
    "print(f'Regressão Logística - Acurácia (Teste): {rf_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada: {scores_rf.mean()}')\n",
    "print(f'Classification Report:\\n{rf_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, rf_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP - Acurácia (Teste): 0.7272727272727273\n",
      "Acurácia média na validação cruzada (MLP): 0.7497712194005948\n",
      "Classification Report MLP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        90\n",
      "           1       0.64      0.51      0.57        41\n",
      "           2       0.75      0.77      0.76        31\n",
      "           3       0.62      0.38      0.47        21\n",
      "           4       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.73       187\n",
      "   macro avg       0.66      0.66      0.65       187\n",
      "weighted avg       0.72      0.73      0.72       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[80  6  2  2  0]\n",
      " [14 21  2  3  1]\n",
      " [ 3  3 24  0  1]\n",
      " [ 5  3  4  8  1]\n",
      " [ 1  0  0  0  3]]\n"
     ]
    }
   ],
   "source": [
    "# Criação e treinamento do MLP com 4 camadas ocultas\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 75, 50, 25), max_iter=500, random_state=seed)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predições no conjunto de treino e teste\n",
    "mlp_predictions_train = mlp_model.predict(X_train)\n",
    "mlp_predictions_test = mlp_model.predict(X_test)\n",
    "\n",
    "# Avaliação MLP\n",
    "mlp_accuracy_train = accuracy_score(y_train, mlp_predictions_train)\n",
    "mlp_accuracy_test = accuracy_score(y_test, mlp_predictions_test)\n",
    "mlp_report = classification_report(y_test, mlp_predictions_test, zero_division=1)\n",
    "\n",
    "# Criar um objeto de validação cruzada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "# Substituir a divisão de treino e teste pelo código de validação cruzada\n",
    "mlp_scores = cross_val_score(mlp_model, dados_pca, df['Type'], cv=cv, scoring='accuracy')\n",
    "\n",
    "# Exibindo resultados do MLP\n",
    "print(f'MLP - Acurácia (Teste): {mlp_accuracy_test}')\n",
    "print(f'Acurácia média na validação cruzada (MLP): {mlp_scores.mean()}')\n",
    "print(f'Classification Report MLP:\\n{mlp_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, mlp_predictions_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ana_v\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4109 - loss: 1.8372 - val_accuracy: 0.4973 - val_loss: 1.4201\n",
      "Epoch 2/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4887 - loss: 1.4032 - val_accuracy: 0.5294 - val_loss: 1.2765\n",
      "Epoch 3/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4989 - loss: 1.2324 - val_accuracy: 0.5775 - val_loss: 1.1448\n",
      "Epoch 4/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5202 - loss: 1.1884 - val_accuracy: 0.5989 - val_loss: 1.1004\n",
      "Epoch 5/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5850 - loss: 0.9948 - val_accuracy: 0.6043 - val_loss: 1.0440\n",
      "Epoch 6/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6229 - loss: 0.9728 - val_accuracy: 0.5829 - val_loss: 0.9659\n",
      "Epoch 7/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6180 - loss: 0.9637 - val_accuracy: 0.6203 - val_loss: 0.9133\n",
      "Epoch 8/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6001 - loss: 0.9108 - val_accuracy: 0.6417 - val_loss: 0.9208\n",
      "Epoch 9/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6269 - loss: 0.8213 - val_accuracy: 0.6417 - val_loss: 0.9235\n",
      "Epoch 10/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.7645 - val_accuracy: 0.6417 - val_loss: 0.9218\n",
      "Epoch 11/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6382 - loss: 0.7951 - val_accuracy: 0.6578 - val_loss: 0.8767\n",
      "Epoch 12/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6897 - loss: 0.7478 - val_accuracy: 0.6364 - val_loss: 0.8508\n",
      "Epoch 13/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6950 - loss: 0.6884 - val_accuracy: 0.6952 - val_loss: 0.8273\n",
      "Epoch 14/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6894 - loss: 0.7141 - val_accuracy: 0.6684 - val_loss: 0.8285\n",
      "Epoch 15/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.6661 - val_accuracy: 0.6364 - val_loss: 0.8851\n",
      "Epoch 16/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7110 - loss: 0.6516 - val_accuracy: 0.6738 - val_loss: 0.9260\n",
      "Epoch 17/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.6229 - val_accuracy: 0.7005 - val_loss: 0.8691\n",
      "Epoch 18/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7370 - loss: 0.6217 - val_accuracy: 0.6417 - val_loss: 0.9292\n",
      "Epoch 19/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7195 - loss: 0.5938 - val_accuracy: 0.6684 - val_loss: 0.9454\n",
      "Epoch 20/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 0.5476 - val_accuracy: 0.6524 - val_loss: 0.9862\n",
      "Epoch 21/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7530 - loss: 0.5113 - val_accuracy: 0.6578 - val_loss: 0.9624\n",
      "Epoch 22/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.4879 - val_accuracy: 0.7059 - val_loss: 0.9968\n",
      "Epoch 23/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7729 - loss: 0.4832 - val_accuracy: 0.6684 - val_loss: 1.2180\n",
      "Epoch 24/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.4766 - val_accuracy: 0.6364 - val_loss: 1.2841\n",
      "Epoch 25/25\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7829 - loss: 0.4721 - val_accuracy: 0.6471 - val_loss: 1.4584\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6568 - loss: 1.4515 \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "unique_types = df['Type'].unique()\n",
    "num_classes = len(unique_types)\n",
    "target_names = [str(cls) for cls in unique_types]\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Função para criar o modelo CNN\n",
    "def create_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(64, 3, activation='relu'),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Validação cruzada\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cross_val_scores = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train):\n",
    "    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "    y_fold_train, y_fold_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    model = create_cnn_model()\n",
    "    history = model.fit(X_fold_train, y_fold_train, epochs=25, batch_size=32, verbose=0, validation_data=(X_fold_val, y_fold_val))\n",
    "\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    cross_val_scores.append(val_accuracy)\n",
    "\n",
    "cross_val_mean = np.mean(cross_val_scores)\n",
    "cross_val_std = np.std(cross_val_scores)\n",
    "\n",
    "# Treinamento final da CNN\n",
    "model = create_cnn_model()\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Avaliação da CNN no conjunto de teste\n",
    "cnn_loss, cnn_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Exibindo resultados da CNN\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "# Predições da CNN no conjunto de teste\n",
    "cnn_predictions = model.predict(X_test)\n",
    "cnn_predictions_classes = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Classification report da CNN\n",
    "cnn_report = classification_report(y_test, cnn_predictions_classes, target_names=target_names, zero_division=1, digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média na validação cruzada (CNN): 0.7154 ± 0.0573\n",
      "Acurácia (Teste): 0.6471\n",
      "Classification Report CNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.96      0.76        90\n",
      "           1       0.62      0.12      0.20        41\n",
      "           2       0.68      0.81      0.74        31\n",
      "           3       1.00      0.24      0.38        21\n",
      "           4       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.65       187\n",
      "   macro avg       0.79      0.42      0.42       187\n",
      "weighted avg       0.68      0.65      0.57       187\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[86  2  2  0  0]\n",
      " [35  5  1  0  0]\n",
      " [ 6  0 25  0  0]\n",
      " [ 8  1  7  5  0]\n",
      " [ 2  0  2  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print(f'Acurácia média na validação cruzada (CNN): {cross_val_mean:.4f} ± {cross_val_std:.4f}')\n",
    "print(f'Acurácia (Teste): {cnn_accuracy:.4f}')\n",
    "print(f'Classification Report CNN:\\n{cnn_report}')\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, cnn_predictions_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
